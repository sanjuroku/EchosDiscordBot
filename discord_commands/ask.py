import asyncio
import discord
import logging
from discord.ext import commands
from discord import app_commands
from typing import Optional
from openai.types.chat import ChatCompletionMessageParam

from utils.gpt_call import gpt_call
from utils.constants import DEFAULT_SYSTEM_PROMPT, MAX_HISTORY, SUMMARY_TRIGGER, DEFAULT_MODEL
from utils.locks import get_user_lock
from utils.auto_summary import summarize_history
from utils.save_and_load import save_histories
from utils.storage import history_storage, summary_storage, role_storage, user_histories, user_summaries, user_roles

# translate_toæ”¯æŒçš„è¯­è¨€åˆ—è¡¨
translate_choices = [
    app_commands.Choice(name="è‹±è¯­ English", value="English"),
    app_commands.Choice(name="æ—¥è¯­ Japanese", value="Japanese"),
    app_commands.Choice(name="éŸ©è¯­ Korean", value="Korean"),
    app_commands.Choice(name="æ³•è¯­ French", value="French"),
    app_commands.Choice(name="å¾·è¯­ German", value="German"),
    app_commands.Choice(name="è¥¿ç­ç‰™è¯­ Spanish", value="Spanish"),
    app_commands.Choice(name="ä¸­æ–‡ Chinese", value="Chinese"),
    app_commands.Choice(name="ä¿„è¯­ Russian", value="Russian"),
    app_commands.Choice(name="æ„å¤§åˆ©è¯­ Italian", value="Italian"),
]

# ============================== #
# /ask æŒ‡ä»¤ï¼ˆå«translate_toåŠŸèƒ½ï¼‰
# ============================== #

def setup(bot: commands.Bot) -> None:
    @bot.tree.command(name="ask", description="å’‹åŠž")
    @app_commands.describe(
        prompt="æƒ³é—®å’‹åŠžçš„å†…å®¹",
        translate_to="ï¼ˆå¯é€‰ï¼‰ç¿»è¯‘ç›®æ ‡è¯­è¨€ï¼ˆä»Žä¸‹æ‹‰é€‰æ‹©ï¼‰",
        translate_to_custom_lang="ï¼ˆå¯é€‰ï¼‰è‡ªè¡Œè¾“å…¥è¯­è¨€åç§°ï¼ˆä¾‹å¦‚ï¼šæ³•è¯­æˆ–è€…Frenchï¼‰"
    )
    @app_commands.choices(translate_to=translate_choices)
    async def ask(
        interaction: discord.Interaction, 
        prompt: str,
        translate_to: Optional[app_commands.Choice[str]] = None,
        translate_to_custom_lang: Optional[str] = None
    ):
        await interaction.response.defer() 
        
        user_id = str(interaction.user.id)
        lock = get_user_lock(user_id)

        async with lock:
            # ============ ç¿»è¯‘æ¨¡å¼ ============ #
            lang = None
            custom_lang = translate_to_custom_lang.strip() if isinstance(translate_to_custom_lang, str) and translate_to_custom_lang.strip() else None
            lang = custom_lang or (translate_to.value if translate_to else None)

            if lang:
                translate_system_prompt = "ä½ æ˜¯ä¸“ä¸šçš„å¤šè¯­ç§ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†ç”¨æˆ·æä¾›çš„æ–‡æœ¬ç¿»è¯‘ä¸ºæŒ‡å®šè¯­è¨€ï¼Œç¡®ä¿æœ¯è¯­å‡†ç¡®ã€è¯­è¨€è‡ªç„¶ï¼Œé¿å…ç›´è¯‘å’Œæœºç¿»ç—•è¿¹ã€‚æ–‡å­¦æ€§æ–‡æœ¬è¯·éµå¾ªâ€œä¿¡ã€è¾¾ã€é›…â€çš„æ ‡å‡†ã€‚ä»…è¿”å›žç¿»è¯‘ç»“æžœï¼Œä¸è¦æ·»åŠ è§£é‡Šæˆ–å¤šä½™å†…å®¹ã€‚"
                translate_user_prompt = f"è¯·å°†ä»¥ä¸‹å†…å®¹ç¿»è¯‘æˆ{lang}ï¼š\n\n{prompt}"

                translate_messages: list[ChatCompletionMessageParam] = [
                    {"role": "system", "content": translate_system_prompt},
                    {"role": "user", "content": translate_user_prompt}
                ]
                
                try:
                    response = await gpt_call(
                        model="gpt-4o",
                        messages=translate_messages,
                        temperature=0.5,
                        max_tokens=1000,
                        timeout=60,
                    )
                    logging.info(f"âœ… æ¨¡åž‹è°ƒç”¨æˆåŠŸï¼š{response.model}")
                    reply = response.choices[0].message.content or "âŒ GPT æ²¡æœ‰è¿”å›žä»»ä½•å†…å®¹å“¦ >.<"
                    await interaction.followup.send(reply)
                    
                    logging.info(f"âœ… ç¿»è¯‘æˆåŠŸï¼š{lang} | ç”¨æˆ· {user_id}\nåŽŸæ–‡ï¼š\n{prompt}\nç¿»è¯‘åŽï¼š\n{reply}")
                    return
                
                except Exception as e:
                    logging.error(f"âŒ ç¿»è¯‘å¤±è´¥ï¼š{e}")
                    
                    await interaction.followup.send(f"âŒ ç¿»è¯‘å¤±è´¥äº†ï¼Œè¯·ç¨åŽé‡è¯• >.<", ephemeral=True)
                    return
            
            # ============ æ™®é€šæé—®æ¨¡å¼ ============ #
            # èŽ·å–åŽ†å²è®°å½•
            history = history_storage.data.get(user_id, [])
            history.append({"role": "user", "content": prompt})

            # è£å‰ªç”¨äºŽèŠå¤©ä¸Šä¸‹æ–‡
            chat_context = history[-MAX_HISTORY:]

            # æž„é€  messages
            messages: list[ChatCompletionMessageParam] = []

            # 1. æ‰€æœ‰æƒ…å†µä¸‹éƒ½åŠ å…¥ user ä¸“å±žæˆ–é»˜è®¤ role
            custom_role = user_roles.get(user_id, "")
            system_prompt = f"{DEFAULT_SYSTEM_PROMPT}\n\n[æˆ‘çš„è‡ªå®šä¹‰è§’è‰²è®¾å®šå¦‚ä¸‹ï¼Œè¯·å‚è€ƒæˆ‘çš„è§’è‰²è®¾å®šï¼š]\n{custom_role}" if custom_role else DEFAULT_SYSTEM_PROMPT
            messages.append({"role": "system", "content": system_prompt})

            # 2. å¦‚æžœæœ‰æ‘˜è¦ï¼Œå†åŠ ä¸€æ¡
            if user_id in user_summaries:
                messages.append({
                    "role":
                    "user",
                    "content":
                    f"[ä»¥ä¸‹æ˜¯æˆ‘çš„èƒŒæ™¯ä¿¡æ¯ï¼Œä¾›ä½ å‚è€ƒ]\n{user_summaries[user_id]}"
                })

            messages.extend(chat_context)

            try:
                # è°ƒç”¨ GPT
                response = await gpt_call(
                    model=DEFAULT_MODEL,
                    messages=messages,  # è°ƒç”¨åŒ…å«æ‘˜è¦çš„å®Œæ•´æ¶ˆæ¯
                    temperature=0.7,
                    max_tokens=1000,
                    timeout=60,
                )
                logging.info(f"âœ… æ¨¡åž‹è°ƒç”¨æˆåŠŸï¼š{response.model}")
                logging.info(f"ç”¨æˆ· {user_id} æé—®ï¼š{prompt}")

                reply = response.choices[0].message.content or "âŒ GPT æ²¡æœ‰è¿”å›žä»»ä½•å†…å®¹å“¦ >.<"

                # æ·»åŠ  AI å›žå¤åˆ°åŽ†å²
                history_storage.data[user_id].append({"role": "assistant", "content": reply})
                # ä¿å­˜
                await asyncio.to_thread(save_histories)

                # å¦‚æžœåŽ†å²å¤ªé•¿åˆ™å…ˆæ‘˜è¦
                if len(history_storage.data[user_id]) >= SUMMARY_TRIGGER:
                    logging.info(f"ðŸ” å½“å‰å®Œæ•´åŽ†å²ï¼š{len(history_storage.data[user_id])}")
                    await summarize_history(user_id)

                await interaction.followup.send(reply)
                logging.info(f"âœ… å›žå¤å·²å‘é€ç»™ç”¨æˆ· {user_id}ï¼Œå½“å‰å®Œæ•´åŽ†å²ï¼š{len(history_storage.data[user_id])}")

            except Exception as e:
                logging.error(f"âŒ GPTè°ƒç”¨å‡ºé”™ï¼š{e}")
                await interaction.followup.send(f"âŒ GPTå¥½åƒå‡ºé”™äº†  >.<", ephemeral=True)
